{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75628551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import re\n",
    "import pandas as pd\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7322635",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "    'Accept-Language': 'en-GB,en-US;q=0.9,en;q=0.8',\n",
    "    'Cache-Control': 'max-age=0',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Cookie': 'Oxford_AcademicMachineID=638040390069998672; SaneID=BqoEqreedUG-dXLHmXq; __gads=ID=3dcd6b1d15431eb8:T=1668442242:S=ALNI_MYk_EJ8t1eJw8Y0V2wZzLGn-SLGWg; oup-cookie=1_14-11-2022; _ga=GA1.3.1652662215.1668442401; hum_oup_visitor=4fcf6c76-6494-4ec6-b9d4-4bf66988ed46; _hjSessionUser_3072445=eyJpZCI6IjA1ODJiOTBiLWJhZDAtNThhNi1iYThjLTYwZGM0OWY4OTg0MyIsImNyZWF0ZWQiOjE2Njg0NDI0MDg1MjEsImV4aXN0aW5nIjp0cnVlfQ==; OUP_SessionId=5erlnfdaxipsft11t5j34hhm; __gpi=UID=00000b7c0ce867b6:T=1668442242:RT=1675133188:S=ALNI_MY8ZT0qP21TcSHDAouJTC6grgw5QQ; _gid=GA1.2.716643929.1675133193; _gid=GA1.3.716643929.1675133193; _hjIncludedInSessionSample=0; _hjSession_3072445=eyJpZCI6Ijc0OGI1OWMxLWUwNGMtNDkzOS05YmNkLTMwYTY3N2M1ZWFkZiIsImNyZWF0ZWQiOjE2NzUxMzU3NDExMjYsImluU2FtcGxlIjpmYWxzZX0=; _hjAbsoluteSessionInProgress=1; _ga=GA1.1.1652662215.1668442401; _ga_GLF90ZEMKF=GS1.1.1675135682.9.1.1675135888.0.0.0; __atuvc=2%7C5; __atuvs=63d88b90b57f13bb000',\n",
    "    'Referer': 'https://academic.oup.com/ecco-jcc/issue/17/Supplement_1?page=2',\n",
    "    'Sec-Fetch-Dest': 'document',\n",
    "    'Sec-Fetch-Mode': 'navigate',\n",
    "    'Sec-Fetch-Site': 'same-origin',\n",
    "    'Sec-Fetch-User': '?1',\n",
    "    'Upgrade-Insecure-Requests': '1',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36',\n",
    "    'sec-ch-ua': '\"Not_A Brand\";v=\"99\", \"Google Chrome\";v=\"109\", \"Chromium\";v=\"109\"',\n",
    "    'sec-ch-ua-mobile': '?0',\n",
    "    'sec-ch-ua-platform': '\"Windows\"',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525b045e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcb2691",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {\n",
    "    'source_id':[],\n",
    "    'manual_id':[],\n",
    "    'article_title':[],\n",
    "    'url':[],\n",
    "    'authors':[],\n",
    "    'author_affiliation':[],\n",
    "    'abstract_text':[],\n",
    "    'date':[],\n",
    "    'start_time':[],\n",
    "    'end_time':[],\n",
    "    'location':[],\n",
    "    'session_title':[],\n",
    "    'session_type':[],\n",
    "    'category':[],\n",
    "    'sub_category':[],\n",
    "    'disclosure':[]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eee189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae189ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for pg in range(1, 8):\n",
    "    \n",
    "    params = {'page': f'{pg}'}\n",
    "    response = requests.get('https://academic.oup.com/ecco-jcc/issue/17/Supplement_1', params=params, headers=headers)\n",
    "    soup = BS(response.content, 'html.parser')\n",
    "    \n",
    "    for i in soup.find_all(class_='al-article-item-wrap al-normal'):\n",
    "\n",
    "        session_link = 'https://academic.oup.com/' + i.find('a').get('href')\n",
    "        print(session_link)\n",
    "\n",
    "        req = requests.get(session_link, headers=headers)\n",
    "        soupin = BS(req.content, 'html.parser') # session ka soup\n",
    "\n",
    "        sess_title_main = soupin.find(class_='article-metadata-tocSections').text.strip().replace('Issue Section:', '').strip()\n",
    "        session_title = soupin.find(class_='wi-article-title article-title-main accessible-content-title at-articleTitle').text.strip()\n",
    "        session_date = soupin.find(class_='ww-citation-date-wrap').text.strip()\n",
    "        session_date = session_date.replace('Published:', '').strip()\n",
    "\n",
    "        # session authors\n",
    "        author = soupin.find(class_='al-authors-list')\n",
    "        session_auth = ''\n",
    "        session_aff = ''\n",
    "\n",
    "        for au in author.find_all(class_='al-author-name-more js-flyout-wrap'):\n",
    "\n",
    "            auth = au.find(class_='linked-name js-linked-name-trigger').text.strip()\n",
    "            affiliation = ''\n",
    "\n",
    "            aff = au.find(class_='info-card-affilitation')\n",
    "            for af in aff.find_all(class_='aff'): # to give spaces br\n",
    "                affiliation += af.text.strip() + ' '\n",
    "\n",
    "            affiliation = affiliation.replace(';', ' ')\n",
    "            session_auth += auth + '; '\n",
    "            session_aff += affiliation + '; '\n",
    "\n",
    "        # abstract text\n",
    "        for ab in soupin.find(class_='abstract').find_all(class_='sec'):\n",
    "            title = ab.find(class_='title').text.strip()\n",
    "            body = ab.text.strip()\n",
    "            body = re.sub(f'^{title}', f'{title} ', body) # give space after title\n",
    "            session_text += body + ' '\n",
    "            \n",
    "        print(f'sess title :- {session_title}')\n",
    "        print(f'sess date :- {session_date}')\n",
    "        print(f'sess auth :- {session_auth}')\n",
    "        \n",
    "        dic['source_id'].append('')\n",
    "        dic['manual_id'].append('')\n",
    "        dic['article_title'].append(session_title)\n",
    "        dic['url'].append(session_link)\n",
    "        dic['authors'].append(session_auth)\n",
    "        dic['author_affiliation'].append(session_aff)\n",
    "        dic['abstract_text'].append(session_text)\n",
    "        dic['date'].append(session_date)\n",
    "        dic['start_time'].append('')\n",
    "        dic['end_time'].append('')\n",
    "        dic['location'].append('')\n",
    "        dic['session_title'].append(sess_title_main)\n",
    "        dic['session_type'].append('')\n",
    "        dic['category'].append('')\n",
    "        dic['sub_category'].append('')\n",
    "        dic['disclosure'].append('')\n",
    "        \n",
    "        print('====')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925eb3ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40a2b75d",
   "metadata": {},
   "source": [
    "## -------------- dusra link session list ------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f18e41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8115b4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "dic = {\n",
    "    'source_id':[],\n",
    "    'manual_id':[],\n",
    "    'article_title':[],\n",
    "    'url':[],\n",
    "    'authors':[],\n",
    "    'author_affiliation':[],\n",
    "    'abstract_text':[],\n",
    "    'date':[],\n",
    "    'start_time':[],\n",
    "    'end_time':[],\n",
    "    'location':[],\n",
    "    'session_id':[],\n",
    "    'news_type':[],\n",
    "    'session_title':[],\n",
    "    'session_type':[],\n",
    "    'category':[],\n",
    "    'sub_category':[],\n",
    "    'disclosure':[],\n",
    "    }\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://cm.ecco-ibd.eu/cmPortal/searchable/EC23/config/normal#!sessionlist/filtered_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62a0bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31e6639",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sco = 1\n",
    "acr = 0\n",
    "for no in range(1, 14):\n",
    "    \n",
    "    sess_id = f'S{sco}'\n",
    "    print(no)\n",
    "    x_path = f'//*[@id=\"cmspg-session-list\"]/blockquote[{no}]/a'\n",
    "    sess_link = driver.find_element(By.XPATH, x_path).get_attribute('href')\n",
    "    print(sess_link)\n",
    "    time.sleep(6)\n",
    "    driver.find_element(By.XPATH, x_path).click()\n",
    "    time.sleep(10)\n",
    "    soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "\n",
    "    #crawlll\n",
    "    # for date time and location at first line\n",
    "    dat_time_loc = soup.find(style='padding:5px;').text.strip().split(',')\n",
    "    sess_date = ' '.join(dat_time_loc[:2])\n",
    "    sess_time = dat_time_loc[2]\n",
    "    sess_loc = dat_time_loc[-1]\n",
    "\n",
    "    # for top block session code session title session type or whatever\n",
    "    sess_category = ''\n",
    "    sess_title = ''\n",
    "    sess_type = ''\n",
    "    for i in soup.find(style='padding:0px 0px 5px 0px;').find_all('div', style='margin-top:5px;'):\n",
    "\n",
    "        if i.text.split(':')[0] == 'Track':\n",
    "            sess_category = ' '.join(i.text.split(':')[1:])\n",
    "        elif i.text.split(':')[0] == 'Session title':\n",
    "            sess_title = ' '.join(i.text.split(':')[1:])\n",
    "        elif i.text.split(':')[0] == 'Programme type':\n",
    "            sess_type = ' '.join(i.text.split(':')[1:])\n",
    "\n",
    "    list_of_presentation = [] # author me press present hai isiliye nikal ke alag se rakh baadme use krege\n",
    "    list_of_xpath_presentation = [] # author me press present hai isiliye nikal ke alag se rakh baadme use krege\n",
    "\n",
    "    # for authors\n",
    "    sess_auth = ''\n",
    "    sess_aff = ''\n",
    "\n",
    "    ci = 0\n",
    "    for i in soup.find(id='cmspg-session-details-presentation-list').children:\n",
    "        ci += 1\n",
    "        if i == '\\n':\n",
    "            continue\n",
    "        if i.find(style='padding:5px 5px'): # if press thn continue\n",
    "            if i.find(style='padding:5px 5px').find('a'):\n",
    "                xp = f'//*[@id=\"cmspg-session-details-presentation-list\"]/div[{ci}]/blockquote/div/div[3]/div[1]/a'\n",
    "                list_of_xpath_presentation.append(xp) # xpath click wala\n",
    "            else:\n",
    "                list_of_presentation.append(i) # bina xpath wala\n",
    "            continue\n",
    "\n",
    "        au_aff = i.find(style='padding:0px 5px').text.strip()\n",
    "        \n",
    "        if re.search('To be confirmed|Tbc', au_aff, flags=re.S):\n",
    "            sess_auth += 'To be confirmed' + '; '\n",
    "            sess_aff += '; '\n",
    "        else:\n",
    "            sess_auth += re.search('(.*),.([A-Z].*)', au_aff).group(1) + '; '\n",
    "            sess_aff += re.search('(.*),.([A-Z].*)', au_aff).group(2) + '; '\n",
    "\n",
    "    \n",
    "    # session abstract text\n",
    "    sess_abstext = ''\n",
    "    if soup.find(class_='bs-callout bs-callout-primary'):\n",
    "        for abst in soup.find(class_='bs-callout bs-callout-primary').find_all('td'):\n",
    "            sess_abstext += abst.text.strip() + '   '\n",
    "        if soup.find(class_='bs-callout bs-callout-primary').find('img'):\n",
    "            logo = soup.find(class_='bs-callout bs-callout-primary').find('img')\n",
    "            sess_abstext += logo.get('src')\n",
    "    \n",
    "    sess_auth = re.sub('; $', '', sess_auth)\n",
    "    sess_aff = re.sub('; $', '', sess_aff)\n",
    "    \n",
    "    print(f'sess date :- {sess_date}')\n",
    "    print(f'sess title :- {sess_title}')\n",
    "    print(f'sess time :- {sess_time}')\n",
    "    print(f'sess loc :- {sess_loc}')\n",
    "    print(f'sess type :- {sess_type}')\n",
    "    print(f'textt :- {sess_abstext}')\n",
    "    print(f'cate :- {sess_category}')\n",
    "    print(f'auth :- {sess_auth}')\n",
    "    print(f'aff :- {sess_aff}')\n",
    "    print('==========='*10)\n",
    "    if sco > 0:\n",
    "        print('append..')\n",
    "        \n",
    "        dic['session_id'].append(sess_id)\n",
    "        dic['news_type'].append('Session') \n",
    "        dic['source_id'].append('')\n",
    "        dic['manual_id'].append('')\n",
    "        dic['article_title'].append(sess_title)\n",
    "        dic['url'].append(sess_link)\n",
    "        dic['authors'].append(sess_auth)\n",
    "        dic['author_affiliation'].append(sess_aff)\n",
    "        dic['abstract_text'].append(sess_abstext)\n",
    "        dic['date'].append(sess_date)\n",
    "        dic['start_time'].append(sess_time)\n",
    "        dic['end_time'].append('')\n",
    "        dic['location'].append(sess_loc)\n",
    "        dic['session_title'].append(sess_title)\n",
    "        dic['session_type'].append(sess_type)\n",
    "        dic['category'].append(sess_category)\n",
    "        dic['sub_category'].append('')\n",
    "        dic['disclosure'].append('')\n",
    "\n",
    "    # presentationsss\n",
    "    for i in list_of_presentation:\n",
    "        try:\n",
    "            art_time = i.find(style='padding-top:5px;display:').text.strip()\n",
    "        except:\n",
    "            art_time = f'no time {sess_time}'\n",
    "        art_title = i.find(style='padding:5px 5px').text.strip()\n",
    "\n",
    "        # art author\n",
    "        art_auth = ''\n",
    "        art_aff = ''\n",
    "        srcid = ''\n",
    "        for au in i.find_all(class_='icon-user'):\n",
    "\n",
    "            if au.parent.get('style') == 'padding: 10px 0px 0px 5px;font-weight: normal;font-size: 85.8%;' or au.parent.get('style') == 'padding: 5px 0px 0px 0px;font-weight: normal;font-size: 14px':\n",
    "                au_aff_ = au.find_next().text.strip()\n",
    "\n",
    "\n",
    "                if re.search('To be confirmed|Tbc', au_aff_, flags=re.S):\n",
    "                    art_auth += 'To be confirmed' + '; '\n",
    "                    art_aff += '; '\n",
    "\n",
    "                elif re.search('\\d.*?\\d', au_aff_): # boht sare author\n",
    "                    print('inifff')\n",
    "                    afflag = False\n",
    "                    authflag = True\n",
    "                    for naya_auth in list(au.find_next().children):\n",
    "\n",
    "                        if authflag:\n",
    "                            art_auth += naya_auth.text.strip() + ' '\n",
    "\n",
    "                        elif afflag:\n",
    "                            art_aff += naya_auth.text.strip() + ' '\n",
    "\n",
    "                        if naya_auth.name == 'br':\n",
    "                            afflag = True\n",
    "                            authflag = False\n",
    "\n",
    "                else:\n",
    "                    if re.search('(.*)-([A-Z].*)', au_aff_): \n",
    "                        art_auth += re.search('(.*)-([A-Z].*)', au_aff_).group(1) + '; '\n",
    "                        art_aff += re.search('(.*)-([A-Z].*)', au_aff_).group(2) + '; '\n",
    "                    else:\n",
    "                        art_auth += re.search('(.*),.([A-Z].*)', au_aff_).group(1) + '; '\n",
    "                        art_aff += re.search('(.*),.([A-Z].*)', au_aff_).group(2) + '; '\n",
    "\n",
    "        if re.search('[A-Z]{1,8}\\d{1,4}:|[A-Z]{1,8}\\d{1,4}[a-z]{1,3}:', art_title):\n",
    "            srcid = re.search('[A-Z]{1,8}\\d{1,4}:|[A-Z]{1,8}\\d{1,4}[a-z]{1,3}:', art_title).group()\n",
    "            art_title = re.sub(f'^{srcid}', '', art_title).strip()\n",
    "            srcid = srcid[:-1]\n",
    "\n",
    "        print(f'art tit :- {srcid} {art_title}')\n",
    "        print(f'art time :- {art_time}')\n",
    "        print(f'art auth :- {art_auth}')\n",
    "        print(f'art aff :- {art_aff}')\n",
    "\n",
    "        art_auth = re.sub('; $', '', art_auth)\n",
    "        art_aff = re.sub('; $', '', art_aff)\n",
    "\n",
    "        \n",
    "        dic['session_id'].append(sess_id)\n",
    "        dic['news_type'].append('Abstract')\n",
    "        dic['source_id'].append(srcid)\n",
    "        dic['manual_id'].append('')\n",
    "        dic['article_title'].append(art_title)\n",
    "        dic['url'].append(sess_link)\n",
    "        dic['authors'].append(art_auth)\n",
    "        dic['author_affiliation'].append(art_aff)\n",
    "        dic['abstract_text'].append('')\n",
    "        dic['date'].append(sess_date)\n",
    "        dic['start_time'].append(art_time)\n",
    "        dic['end_time'].append('')\n",
    "        dic['location'].append(sess_loc)\n",
    "        dic['session_title'].append(sess_title)\n",
    "        dic['session_type'].append(sess_type)\n",
    "        dic['category'].append(sess_category)\n",
    "        dic['sub_category'].append('')\n",
    "        dic['disclosure'].append('')\n",
    "\n",
    "        print('==*='*22)\n",
    "    # xpath wala presentation...\n",
    "    ou = 0\n",
    "    for i in list_of_xpath_presentation[acr:]:\n",
    "\n",
    "        time.sleep(10)\n",
    "\n",
    "        try:\n",
    "            abs_link = driver.find_element(By.XPATH, i).get_attribute('href')\n",
    "            print(abs_link)\n",
    "            driver.find_element(By.XPATH, i).click()\n",
    "\n",
    "        except:            \n",
    "            ni = i.replace('//*[@id=\"cmspg-session-details-presentation-list\"]/div[', '')\n",
    "            ni = re.search('(\\d{1,3})]/.*', ni).group(1)\n",
    "            \n",
    "            new_x = f'//*[@id=\"cmspg-session-details-presentation-list\"]/div[{ni}]/blockquote/div/div[4]/div[1]/a'\n",
    "            abs_link = driver.find_element(By.XPATH, new_x).get_attribute('href')\n",
    "            print(abs_link)\n",
    "            print(new_x)\n",
    "            driver.find_element(By.XPATH, new_x).click()\n",
    "\n",
    "\n",
    "        time.sleep(8)\n",
    "        pre_soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "        cat_no = ''\n",
    "        pre_no = ''\n",
    "        sess_type = ''\n",
    "        sess_title = ''\n",
    "        art_title = pre_soup.find('h4').next_sibling\n",
    "\n",
    "        for i in pre_soup.find_all(style='margin-top:5px;'):\n",
    "\n",
    "            if i.text.split(':')[0] == 'Catalog number':\n",
    "                cat_no = ' '.join(i.text.split(':')[1:]).strip()\n",
    "            elif i.text.split(':')[0] == 'Presentation number':\n",
    "                pre_no = ' '.join(i.text.split(':')[1:]).strip()\n",
    "            elif i.text.split(':')[0] == 'Session type':\n",
    "                sess_type = ' '.join(i.text.split(':')[1:]).strip()\n",
    "            elif i.text.split(':')[0] == 'Session title':\n",
    "                sess_title = ' '.join(i.text.split(':')[1:]).strip()\n",
    "\n",
    "        art_author = ''\n",
    "        art_abstext = ''\n",
    "\n",
    "        if len(pre_soup.find_all(class_='bs-callout bs-callout-primary')):\n",
    "\n",
    "            # title hai or biography hai\n",
    "            # biography filling\n",
    "        #     for bio in pre_soup.find_all(class_='bs-callout bs-callout-primary')[-1].find_all():\n",
    "            art_abstext += pre_soup.find_all(class_='bs-callout bs-callout-primary')[-1].text + ' '\n",
    "            abs_flag = False\n",
    "            auth_flag = True\n",
    "            for i in pre_soup.find_all(class_='bs-callout bs-callout-primary')[-1].next_siblings:\n",
    "\n",
    "                if re.search('Background.*', i.text, flags=re.S):\n",
    "                    abs_flag = True\n",
    "                    auth_flag = False\n",
    "\n",
    "                if auth_flag:\n",
    "                    art_author += i.text\n",
    "                elif abs_flag and type(i) == bs4.element.Tag:\n",
    "                    art_abstext += i.text.strip() + ' '\n",
    "\n",
    "        else:\n",
    "            for i in pre_soup.find_all(class_='bs-callout bs-callout-primary')[-1].next_siblings:\n",
    "\n",
    "                if re.search('Background.*', i.text, flags=re.S):\n",
    "                    abs_flag = True\n",
    "                    auth_flag = False\n",
    "\n",
    "                if auth_flag:\n",
    "                    art_author += i.text\n",
    "                elif abs_flag and type(i) == bs4.element.Tag:\n",
    "                    art_abstext += i.text.strip() + ' '\n",
    "\n",
    "        src_id = cat_no + '; ' + pre_no\n",
    "        \n",
    "        \n",
    "        print(f'src id :- {src_id}')\n",
    "        print(f'sess type :- {sess_type}')\n",
    "        print(f'sess title :- {sess_title}')\n",
    "        print(f'art title :- {art_title}')\n",
    "        print(f'author :- {art_author}')\n",
    "        print(f'abs text :- {art_abstext}')\n",
    "        print('==*='*22)\n",
    "\n",
    "        dic['session_id'].append(sess_id)\n",
    "        dic['news_type'].append('Abstract')\n",
    "        dic['source_id'].append(src_id)\n",
    "        dic['manual_id'].append('')\n",
    "        dic['article_title'].append(art_title)\n",
    "        dic['url'].append(abs_link)\n",
    "        dic['authors'].append(art_author)\n",
    "        dic['author_affiliation'].append('')\n",
    "        dic['abstract_text'].append(art_abstext)\n",
    "        dic['date'].append(sess_date)\n",
    "        dic['start_time'].append(sess_time)\n",
    "        dic['end_time'].append('')\n",
    "        dic['location'].append(sess_loc)\n",
    "        dic['session_title'].append(sess_title)\n",
    "        dic['session_type'].append(sess_type)\n",
    "        dic['category'].append(sess_category)\n",
    "        dic['sub_category'].append('')\n",
    "        dic['disclosure'].append('')\n",
    "\n",
    "        time.sleep(4)\n",
    "        driver.back()\n",
    "        time.sleep(5)\n",
    "        ou += 1\n",
    "\n",
    "    driver.back()\n",
    "    time.sleep(7)\n",
    "    \n",
    "    sco += 1\n",
    "    acr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2027b86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b549cd10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dic)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3606d379",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('ECCO_sess.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae97a1e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee971757",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0d3b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16637830",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_excel('ECCO_1stl.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29f77db",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### ----------- one link -------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2845055b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "dic = {\n",
    "    'source_id':[],\n",
    "    'manual_id':[],\n",
    "    'article_title':[],\n",
    "    'url':[],\n",
    "    'authors':[],\n",
    "    'author_affiliation':[],\n",
    "    'abstract_text':[],\n",
    "    'date':[],\n",
    "    'start_time':[],\n",
    "    'end_time':[],\n",
    "    'location':[],\n",
    "    'session_id':[],\n",
    "    'news_type':[],\n",
    "    'session_title':[],\n",
    "    'session_type':[],\n",
    "    'category':[],\n",
    "    'sub_category':[],\n",
    "    'disclosure':[],\n",
    "    }\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://cm.ecco-ibd.eu/cmPortal/searchable/EC23/config/normal#!sessiondetails/0000027230_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23965ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sco = 1\n",
    "acr = 0\n",
    "    \n",
    "sess_id = f'S{sco}'\n",
    "soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "\n",
    "#crawlll\n",
    "# for date time and location at first line\n",
    "dat_time_loc = soup.find(style='padding:5px;').text.strip().split(',')\n",
    "sess_date = ' '.join(dat_time_loc[:2])\n",
    "sess_time = dat_time_loc[2]\n",
    "sess_loc = dat_time_loc[-1]\n",
    "\n",
    "# for top block session code session title session type or whatever\n",
    "sess_category = ''\n",
    "sess_title = ''\n",
    "sess_type = ''\n",
    "for i in soup.find(style='padding:0px 0px 5px 0px;').find_all('div', style='margin-top:5px;'):\n",
    "\n",
    "    if i.text.split(':')[0] == 'Track':\n",
    "        sess_category = ' '.join(i.text.split(':')[1:])\n",
    "    elif i.text.split(':')[0] == 'Session title':\n",
    "        sess_title = ' '.join(i.text.split(':')[1:])\n",
    "    elif i.text.split(':')[0] == 'Programme type':\n",
    "        sess_type = ' '.join(i.text.split(':')[1:])\n",
    "\n",
    "list_of_presentation = [] # author me press present hai isiliye nikal ke alag se rakh baadme use krege\n",
    "list_of_xpath_presentation = [] # author me press present hai isiliye nikal ke alag se rakh baadme use krege\n",
    "\n",
    "# for authors\n",
    "sess_auth = ''\n",
    "sess_aff = ''\n",
    "\n",
    "ci = 0\n",
    "for i in soup.find(id='cmspg-session-details-presentation-list').children:\n",
    "    ci += 1\n",
    "    if i.find(style='padding:5px 5px'): # if press thn continue\n",
    "        if i.find(style='padding:5px 5px').find('a'):\n",
    "            xp = f'//*[@id=\"cmspg-session-details-presentation-list\"]/div[{ci}]/blockquote/div/div[3]/div[1]/a'\n",
    "            list_of_xpath_presentation.append(xp) # xpath click wala\n",
    "        else:\n",
    "            list_of_presentation.append(i) # bina xpath wala\n",
    "        continue\n",
    "\n",
    "    au_aff = i.find(style='padding:0px 5px').text.strip()\n",
    "\n",
    "    if re.search('To be confirmed|Tbc', au_aff, flags=re.S):\n",
    "        sess_auth += 'To be confirmed' + '; '\n",
    "        sess_aff += '; '\n",
    "    else:\n",
    "        sess_auth += re.search('(.*),.([A-Z].*)', au_aff).group(1) + '; '\n",
    "        sess_aff += re.search('(.*),.([A-Z].*)', au_aff).group(2) + '; '\n",
    "\n",
    "\n",
    "# session abstract text\n",
    "sess_abstext = ''\n",
    "if soup.find(class_='bs-callout bs-callout-primary'):\n",
    "    for abst in soup.find(class_='bs-callout bs-callout-primary').find_all('td'):\n",
    "        sess_abstext += abst.text.strip() + '   '\n",
    "    if soup.find(class_='bs-callout bs-callout-primary').find('img'):\n",
    "        logo = soup.find(class_='bs-callout bs-callout-primary').find('img')\n",
    "        sess_abstext += logo.get('src')\n",
    "\n",
    "sess_auth = re.sub('; $', '', sess_auth)\n",
    "sess_aff = re.sub('; $', '', sess_aff)\n",
    "\n",
    "print(f'sess date :- {sess_date}')\n",
    "print(f'sess title :- {sess_title}')\n",
    "print(f'sess time :- {sess_time}')\n",
    "print(f'sess loc :- {sess_loc}')\n",
    "print(f'sess type :- {sess_type}')\n",
    "print(f'textt :- {sess_abstext}')\n",
    "print(f'cate :- {sess_category}')\n",
    "print(f'auth :- {sess_auth}')\n",
    "print(f'aff :- {sess_aff}')\n",
    "print('==========='*10)\n",
    "if sco > 0:\n",
    "    print('append..')\n",
    "\n",
    "    dic['session_id'].append(sess_id)\n",
    "    dic['news_type'].append('Session')\n",
    "    dic['source_id'].append('')\n",
    "    dic['manual_id'].append('')\n",
    "    dic['article_title'].append(sess_title)\n",
    "    dic['url'].append('https://cm.ecco-ibd.eu/cmPortal/searchable/EC23/config/normal#!sessiondetails/0000027230_0')\n",
    "    dic['authors'].append(sess_auth)\n",
    "    dic['author_affiliation'].append(sess_aff)\n",
    "    dic['abstract_text'].append(sess_abstext)\n",
    "    dic['date'].append(sess_date)\n",
    "    dic['start_time'].append(sess_time)\n",
    "    dic['end_time'].append('')\n",
    "    dic['location'].append(sess_loc)\n",
    "    dic['session_title'].append(sess_title)\n",
    "    dic['session_type'].append(sess_type)\n",
    "    dic['category'].append(sess_category)\n",
    "    dic['sub_category'].append('')\n",
    "    dic['disclosure'].append('')\n",
    "\n",
    "# presentationsss\n",
    "for i in list_of_presentation:\n",
    "    try:\n",
    "        art_time = i.find(style='padding-top:5px;display:').text.strip()\n",
    "    except:\n",
    "        art_time = f'no time {sess_time}'\n",
    "    art_title = i.find(style='padding:5px 5px').text.strip()\n",
    "\n",
    "    # art author\n",
    "    art_auth = ''\n",
    "    art_aff = ''\n",
    "    srcid = ''\n",
    "    for au in i.find_all(class_='icon-user'):\n",
    "    \n",
    "        if au.parent.get('style') == 'padding: 10px 0px 0px 5px;font-weight: normal;font-size: 85.8%;' or au.parent.get('style') == 'padding: 5px 0px 0px 0px;font-weight: normal;font-size: 14px':\n",
    "            au_aff_ = au.find_next().text.strip()\n",
    "\n",
    "            \n",
    "            if re.search('To be confirmed|Tbc', au_aff_, flags=re.S):\n",
    "                art_auth += 'To be confirmed' + '; '\n",
    "                art_aff += '; '\n",
    "                \n",
    "            elif re.search('\\d.*?\\d', au_aff_): # boht sare author\n",
    "                print('inifff')\n",
    "                afflag = False\n",
    "                authflag = True\n",
    "                for naya_auth in list(au.find_next().children):\n",
    "\n",
    "                    if authflag:\n",
    "                        art_auth += naya_auth.text.strip() + ' '\n",
    "\n",
    "                    elif afflag:\n",
    "                        art_aff += naya_auth.text.strip() + ' '\n",
    "\n",
    "                    if naya_auth.name == 'br':\n",
    "                        afflag = True\n",
    "                        authflag = False\n",
    "\n",
    "            else:\n",
    "                if re.search('(.*)-([A-Z].*)', au_aff_): \n",
    "                    art_auth += re.search('(.*)-([A-Z].*)', au_aff_).group(1) + '; '\n",
    "                    art_aff += re.search('(.*)-([A-Z].*)', au_aff_).group(2) + '; '\n",
    "                else:\n",
    "                    art_auth += re.search('(.*),.([A-Z].*)', au_aff_).group(1) + '; '\n",
    "                    art_aff += re.search('(.*),.([A-Z].*)', au_aff_).group(2) + '; '\n",
    "\n",
    "    if re.search('[A-Z]{1,8}\\d{1,4}:|[A-Z]{1,8}\\d{1,4}[a-z]{1,3}:', art_title):\n",
    "        srcid = re.search('[A-Z]{1,8}\\d{1,4}:|[A-Z]{1,8}\\d{1,4}[a-z]{1,3}:', art_title).group()\n",
    "        art_title = re.sub(f'^{srcid}', '', art_title).strip()\n",
    "        srcid = srcid[:-1]\n",
    "\n",
    "    print(f'art tit :- {srcid} {art_title}')\n",
    "    print(f'art time :- {art_time}')\n",
    "    print(f'art auth :- {art_auth}')\n",
    "    print(f'art aff :- {art_aff}')\n",
    "\n",
    "    art_auth = re.sub('; $', '', art_auth)\n",
    "    art_aff = re.sub('; $', '', art_aff)\n",
    "\n",
    "    dic['session_id'].append(sess_id)\n",
    "    dic['news_type'].append('Abstract')\n",
    "    dic['source_id'].append(srcid)\n",
    "    dic['manual_id'].append('')\n",
    "    dic['article_title'].append(art_title)\n",
    "    dic['url'].append('https://cm.ecco-ibd.eu/cmPortal/searchable/EC23/config/normal#!sessiondetails/0000027230_0')\n",
    "    dic['authors'].append(art_auth)\n",
    "    dic['author_affiliation'].append(art_aff)\n",
    "    dic['abstract_text'].append('')\n",
    "    dic['date'].append(sess_date)\n",
    "    dic['start_time'].append(art_time)\n",
    "    dic['end_time'].append('')\n",
    "    dic['location'].append(sess_loc)\n",
    "    dic['session_title'].append(sess_title)\n",
    "    dic['session_type'].append(sess_type)\n",
    "    dic['category'].append(sess_category)\n",
    "    dic['sub_category'].append('')\n",
    "    dic['disclosure'].append('')\n",
    "\n",
    "    print('==*='*22)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab4c39e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dic)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a109cd82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_excel('ekLink.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cf737f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e50271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1ce1780",
   "metadata": {},
   "source": [
    "### ------ json se session wala.. pr session author ka prob ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29faf6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import re\n",
    "\n",
    "cookies = {\n",
    "    '_ga': 'GA1.2.1938457060.1675133206',\n",
    "    '__RequestVerificationToken_L2NtU2VhcmNoYWJsZVByb2dyYW1tZQ2': 'msjzHywGusF-N9HcmAPYaZum6ePHOSOtHkU4HBnjhIo_DJA-8uHvcBAr2SnYFOvnM8dMULOgeb13A9iLdJFp9zK9iVKACY4jp9Scc7rKkiA1',\n",
    "    '_gid': 'GA1.2.1022988265.1676831836',\n",
    "    '_gat_gtag_UA_xxxxxx_1': '1',\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    'Accept': '*/*',\n",
    "    'Accept-Language': 'en-GB,en-US;q=0.9,en;q=0.8',\n",
    "    'Authorization': 'Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1bmlxdWVfbmFtZSI6ImFub255bW91cyIsIm5iZiI6MTY3NjgzODEyMCwiZXhwIjoxNjc2OTI0NTIwLCJpYXQiOjE2NzY4MzgxMjAsImlzcyI6ImVjY28taWJkIiwiYXVkIjoiY21zcGcifQ.6JXKuev23stPz1u1XLX_oJnkfy48qvZGSibduRXF5EI',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Content-Type': 'application/json; charset=UTF-8',\n",
    "    # 'Cookie': '_ga=GA1.2.1938457060.1675133206; __RequestVerificationToken_L2NtU2VhcmNoYWJsZVByb2dyYW1tZQ2=msjzHywGusF-N9HcmAPYaZum6ePHOSOtHkU4HBnjhIo_DJA-8uHvcBAr2SnYFOvnM8dMULOgeb13A9iLdJFp9zK9iVKACY4jp9Scc7rKkiA1; _gid=GA1.2.1022988265.1676831836; _gat_gtag_UA_xxxxxx_1=1',\n",
    "    'Origin': 'https://cm.ecco-ibd.eu',\n",
    "    'Referer': 'https://cm.ecco-ibd.eu/cmPortal/searchable/EC23/config/normal',\n",
    "    'Sec-Fetch-Dest': 'empty',\n",
    "    'Sec-Fetch-Mode': 'cors',\n",
    "    'Sec-Fetch-Site': 'same-origin',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36',\n",
    "    'X-Requested-With': 'XMLHttpRequest',\n",
    "    'covr-cmhost-customer': 'EC23',\n",
    "    'covr-cmhost-function': 'normal',\n",
    "    'sec-ch-ua': '\"Not_A Brand\";v=\"99\", \"Google Chrome\";v=\"109\", \"Chromium\";v=\"109\"',\n",
    "    'sec-ch-ua-mobile': '?0',\n",
    "    'sec-ch-ua-platform': '\"Windows\"',\n",
    "}\n",
    "\n",
    "json_data_pass = {\n",
    "    'model': '{\"filterbySessionTypeIds\":[],\"filterbyTrackIds\":[],\"filterbyFunctionTypeIds\":[],\"filterbyKeywordsIds\":[],\"searchWordsInSessionObjectives\":\"\",\"searchWordsInSubject\":\"\",\"searchContactOrAuthorName\":\"\",\"searchWordsInAbstractTitleOrText\":\"\",\"searchCatalogOrPresentationNumber\":\"\",\"searchOtherKeywords\":\"\",\"isMyItineraryEnabled\":false,\"isMyFavouritesEnabled\":false}',\n",
    "    'key': 'NORMAL',\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "    'https://cm.ecco-ibd.eu/cmsearchableprogramme/conferencemanager/CM_W3_SearchableProgram/api/persionid/anonymous/type/normal/getfilteredsessions/conference/ec23',\n",
    "    cookies=cookies,\n",
    "    headers=headers,\n",
    "    json=json_data_pass,\n",
    ")\n",
    "\n",
    "json_alldata = response.json()\n",
    "\n",
    "\n",
    "co = 0\n",
    "for json_data in json_alldata['sessions']:\n",
    "    \n",
    "    \n",
    "    session_url = json_data['@id']\n",
    "    session_url = re.search('session_(.*)', session_url).group(1)\n",
    "#     if session_url == '0000027230_0':\n",
    "#         print('break')\n",
    "#         break\n",
    "    session_url = f'https://cm.ecco-ibd.eu/cmPortal/searchable/EC23/config/normal#!sessiondetails/{session_url}'\n",
    "    print(session_url)\n",
    "    \n",
    "    session_type = json_data['sessionTypeDescription']\n",
    "    session_title = json_data['description']\n",
    "    session_date = json_data['start'].split('T')[0]\n",
    "    sess_s_time = json_data['start'].split('T')[1][:-3]\n",
    "    sess_e_time = json_data['end'].split('T')[1][:-3]\n",
    "    session_category = ''\n",
    "    if json_data['trackDescription']:\n",
    "        session_category = json_data['trackDescription']\n",
    "        \n",
    "    session_location = json_data['roomName']\n",
    "    sess_abstext = ''\n",
    "    sess_auth = ''\n",
    "    sess_aff = ''\n",
    "\n",
    "    soup = BS(json_data['intro'], 'html.parser')\n",
    "\n",
    "    for abst in soup.find_all('td'):\n",
    "        sess_abstext += abst.text.strip() + '   '\n",
    "    if soup.find('img'):\n",
    "        logo = soup.find('img')\n",
    "        sess_abstext += logo.get('src')\n",
    "\n",
    "    print(f'sess date :- {session_date}')\n",
    "    print(f'sess title :- {session_title}')\n",
    "    print(f'sess time :- {sess_s_time} {sess_e_time}')\n",
    "    print(f'sess loc :- {session_location}')\n",
    "    print(f'sess type :- {session_type}')\n",
    "    print(f'textt :- {sess_abstext}')\n",
    "    print(f'cate :- {session_category}')\n",
    "    print(f'auth :- {sess_auth}')\n",
    "    print(f'aff :- {sess_aff}')\n",
    "    print('===='*20)\n",
    "\n",
    "    # ------------ presentation --------------------\\\n",
    "    for pre in json_data['presentations']:\n",
    "\n",
    "        art_title = pre['subject']\n",
    "        art_id = pre['presentationNumber']\n",
    "        stime = ''\n",
    "        etime = ''\n",
    "\n",
    "        art_s_time = pre['start']\n",
    "        if art_s_time:\n",
    "            stime = art_s_time.split('T')[1][:-3]\n",
    "\n",
    "        art_e_time = pre['end']\n",
    "        if art_e_time:\n",
    "            etime = art_e_time.split('T')[1][:-3]\n",
    "\n",
    "        art_author = pre['personFirstName'] + ' ' + pre['personLastName']\n",
    "        art_aff = pre['personCountry']\n",
    "\n",
    "\n",
    "        print(f'art title :- {art_id} -- {art_title}')\n",
    "        print('art time :- ', stime, etime)\n",
    "        print(f'art auth :- {art_author}')\n",
    "        print(f'art aff :- {art_aff}')\n",
    "        print('==**='*20)\n",
    "\n",
    "        co += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ac8447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6482daec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c470b09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5527e93d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
