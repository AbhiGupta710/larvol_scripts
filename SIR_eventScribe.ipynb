{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c422c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mistakes in aff wit disclosure, article have its own category, missing affiliation , auth mismatch, abs text missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0efae9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "\n",
    "dic = {\n",
    "    'source_id':[],\n",
    "    'manual_id':[],\n",
    "    'article_title':[],\n",
    "    'url':[],\n",
    "    'authors':[],\n",
    "    'author_affiliation':[],\n",
    "    'abstract_text':[],\n",
    "    'date':[],\n",
    "    'start_time':[],\n",
    "    'end_time':[],\n",
    "    'location':[],\n",
    "    'session_id':[],\n",
    "    'news_type':[],\n",
    "    'session_title':[],\n",
    "    'session_type':[],\n",
    "    'category':[],\n",
    "    'sub_category':[],\n",
    "    'disclosure':[]\n",
    "    }\n",
    "\n",
    "req1 = requests.get(\"https://www.eventscribe.net/2023/SIR23/agenda.asp?pfp=BrowsebyDay\")\n",
    "soup = BeautifulSoup(req1.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63029e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ada8ecc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "se = set()\n",
    "c = 0\n",
    "for i in soup.find_all(class_=re.compile('list-group-item.*')):\n",
    "    \n",
    "    \n",
    "    session_number = f'S{c+1}'\n",
    "    code = i.get('data-presid')\n",
    "    print(code)\n",
    "    if code == '1177784':\n",
    "        \n",
    "        if str(code) == 'None':\n",
    "            continue\n",
    "        icon = ''\n",
    "        if i.find_all('img'): # check if there is any icon\n",
    "            print('yesss iconn......')\n",
    "            for i in i.find_all('img'):\n",
    "                icon += i.get('title') + '; '\n",
    "\n",
    "        session_url = f'https://www.eventscribe.net/2023/SIR23/fsPopup.asp?Mode=sessioninfo&PresentationID={code}'\n",
    "        if code in se:\n",
    "            print('in se :-', code)\n",
    "            continue\n",
    "        req = requests.get(session_url)\n",
    "        soup = BeautifulSoup(req.content, 'html.parser')\n",
    "\n",
    "\n",
    "        print(session_url)\n",
    "        session_title = soup.find('h1').text.strip()\n",
    "        session_date = soup.find(class_='pull-left pres-tidbit tipsytip').text.strip()\n",
    "        ses_time_loc = soup.find_all(class_='pull-left pres-tidbit')\n",
    "        session_time = ses_time_loc[0].text.strip()\n",
    "\n",
    "        if len(ses_time_loc) > 1:\n",
    "            session_loc = ses_time_loc[1].text.strip()\n",
    "        else:\n",
    "            print('no location....')\n",
    "            session_loc = ''\n",
    "\n",
    "        session_loc = re.sub('Location:', '', session_loc)\n",
    "\n",
    "        sess_text = ''\n",
    "        session_author = ''\n",
    "        affiliation = ''\n",
    "        sess_type = ''\n",
    "        category = ''\n",
    "        sess_disclose = ''\n",
    "\n",
    "        cat = soup.find_all(class_='trackname innertracks')\n",
    "        if len(cat) < 1:\n",
    "            cat = soup.find_all(style='color:#FFFFFF;font-size:14px; margin-top:10px; margin-right:10px; background:#489CD8')\n",
    "\n",
    "        try:\n",
    "            sess_type = soup.find(style='color:#FFFFFF; font-size:14px; margin-top:10px; margin-right:10px; background:#489CD8;').text.strip()\n",
    "        except:\n",
    "            try:\n",
    "                sess_type = soup.find(style='margin-top:10px;').text.strip()\n",
    "            except:\n",
    "                sess_type = ''\n",
    "\n",
    "        for i in cat:\n",
    "            category += i.text.strip() + '; '\n",
    "\n",
    "        auth = soup.find(class_='speakers-wrap')\n",
    "\n",
    "        for s_i in auth.find_all(class_='row'): # author affiliation\n",
    "            aut = s_i.find(class_='col-xs-12 col-md-6').a.text\n",
    "            aff = s_i.find(class_=\"text-muted prof-text\")\n",
    "            aff = re.split('<br.*?>', str(aff))\n",
    "            aff = ' '.join(aff)\n",
    "            if re.search('<p class=\"text-muted prof-text\">(.*?)</p>', aff, flags=re.S):\n",
    "                aff = re.search('<p class=\"text-muted prof-text\">(.*?)</p>', aff, flags=re.S).group(1)\n",
    "            else:\n",
    "                aff = ' '\n",
    "            session_author += aut.strip() + '; '\n",
    "            affiliation += aff + '; '\n",
    "        if soup.find_all(class_='presentation-disclosure-block'):\n",
    "            for i in soup.find_all(class_='presentation-disclosure-block')[1:]: # disclosure filling\n",
    "\n",
    "                dis = i.text.strip()\n",
    "                dis = dis.replace(';', ' ')\n",
    "                sess_disclose += dis + '; '\n",
    "\n",
    "        try: # abs_text with giving spaces\n",
    "            sess_text = soup.find(class_='PresentationAbstractText mar-top')\n",
    "            sess_text = str(sess_text)\n",
    "            sess_text = BeautifulSoup(sess_text, 'html.parser').text\n",
    "        except:\n",
    "            sess_text = ''\n",
    "        if str(sess_text) == 'None':\n",
    "            sess_text = ''\n",
    "\n",
    "        if session_title == sess_type:\n",
    "            sess_type = ' '\n",
    "            print('check if.......')\n",
    "            \n",
    "        if re.search('Disclosure|disclosu', affiliation, flags=re.S):\n",
    "            affiliation = re.sub('Disclosure.*|disclosu.*', '', affiliation, flags=re.S)\n",
    "\n",
    "        category = re.sub(sess_type+'; ', '', category)\n",
    "        print(f'session title :- {session_title}')\n",
    "        print(f'session type :- {sess_type}')\n",
    "        print(f'category :- {category}')\n",
    "        print(f'session date :- {session_date}')\n",
    "        print(f'session time :- {session_time}')\n",
    "        print(f'session location :- {session_loc}')\n",
    "        print(f'session author :- {session_author}')\n",
    "        print(f'session aff :- {affiliation}')\n",
    "        print(f'session text :- {sess_text}')\n",
    "\n",
    "        print('======================='*5)\n",
    "\n",
    "        dic['session_id'].append(session_number)\n",
    "        dic['news_type'].append('Session')\n",
    "        dic['source_id'].append('')\n",
    "        dic['manual_id'].append('')\n",
    "        dic['article_title'].append(session_title)\n",
    "        dic['url'].append(session_url)\n",
    "        dic['authors'].append(session_author)\n",
    "        dic['author_affiliation'].append(affiliation)\n",
    "        dic['abstract_text'].append(sess_text)\n",
    "        dic['date'].append(session_date)\n",
    "        dic['start_time'].append(session_time.split('–')[0])\n",
    "        dic['end_time'].append(session_time.split('–')[1])\n",
    "        dic['location'].append(session_loc)\n",
    "        dic['session_title'].append(session_title)\n",
    "        dic['session_type'].append(sess_type)\n",
    "        dic['category'].append(category)\n",
    "        dic['sub_category'].append('')\n",
    "        dic['disclosure'].append(sess_disclose)\n",
    "\n",
    "\n",
    "        for i in re.split(\"li class='list-group-item '\", req.text)[1:]: # article links\n",
    "\n",
    "            url = re.search(\"data-presid='(.*?)' data-url\", i).group(1)\n",
    "            article_url = f'https://www.eventscribe.net/2023/SIR23/fsPopup.asp?Mode=presInfo&PresentationID={url}'\n",
    "            print(article_url)\n",
    "            req_art = requests.get(article_url)\n",
    "            soup = BeautifulSoup(req_art.content, 'html.parser')\n",
    "\n",
    "            se.add(url)\n",
    "            article_cat = category\n",
    "            cat = soup.find_all(style='background:#489CD8; color:#FFFFFF; font-size:14px; margin-top:10px; margin-right:10px;')\n",
    "            if len(cat) < 1:\n",
    "                cat = soup.find_all(style='color:#FFFFFF;font-size:14px; margin-top:10px; margin-right:10px; background:#489CD8')\n",
    "\n",
    "            for i in cat:\n",
    "                article_cat += i.text.strip() + '; '\n",
    "\n",
    "            article_title = soup.find('h1', style='margin-top:10px;').text.strip()\n",
    "            article_date = soup.find('div', class_='pull-left pres-tidbit tipsytip').text.strip()\n",
    "            article_author = ''\n",
    "            article_aff = ''\n",
    "            article_abs_text = ''\n",
    "            art_disclose = ''\n",
    "\n",
    "            time_loc = soup.find_all(class_='pull-left pres-tidbit')\n",
    "            art_time = time_loc[0].text.strip()\n",
    "            art_auth = soup.find(class_='speakers-wrap')\n",
    "\n",
    "            for a_i in art_auth.find_all(class_='row'): # author affiliation\n",
    "                aut = a_i.find(class_='col-xs-12 col-md-6').a.text\n",
    "                aff = a_i.find(class_=\"text-muted prof-text\")\n",
    "                aff = re.split('<br.*?>', str(aff))\n",
    "                aff = ' '.join(aff)\n",
    "                if re.search('<p class=\"text-muted prof-text\">(.*?)</p>', aff, flags=re.S):\n",
    "                    aff = re.search('<p class=\"text-muted prof-text\">(.*?)</p>', aff, flags=re.S).group(1)\n",
    "                else:\n",
    "                    aff = ' '\n",
    "                article_author += aut.strip() + '; '\n",
    "                article_aff += aff + '; '\n",
    "\n",
    "            if soup.find_all(class_='presentation-disclosure-block'):\n",
    "                for i in soup.find_all(class_='presentation-disclosure-block')[1:]: # disclosure filling\n",
    "\n",
    "                    dis = i.text.strip()\n",
    "                    dis = dis.replace(';', ' ')\n",
    "                    art_disclose += dis + '; '\n",
    "            try:\n",
    "                article_abs_text = soup.find(class_='PresentationAbstractText mar-top')\n",
    "                article_abs_text = str(article_abs_text)\n",
    "                article_abs_text = article_abs_text.replace('<b>', '')\n",
    "                article_abs_text = article_abs_text.replace('</b>', '')\n",
    "                article_abs_text = re.split('<br.*?>', article_abs_text)\n",
    "                article_abs_text = ' '.join(article_abs_text)\n",
    "                article_abs_text = re.search('<div class=\"PresentationAbstractText mar-top\">(.*?)</div>', article_abs_text).group(1)\n",
    "                article_abs_text = BeautifulSoup(article_abs_text, 'html.parser').text\n",
    "            except:\n",
    "                article_abs_text = ''\n",
    "            \n",
    "            if re.search('Disclosure|disclosu', article_aff, flags=re.S):\n",
    "                article_aff = re.sub('Disclosure.*|disclosu.*', '', article_aff, flags=re.S)\n",
    "\n",
    "            print(article_title)\n",
    "            print(article_date)\n",
    "            print(art_time)\n",
    "            print(article_author)\n",
    "            print(article_aff)\n",
    "            print(f'article text :- {article_abs_text}')\n",
    "            print(f'dusra column :- {article_cat}')\n",
    "\n",
    "            dic['session_id'].append(session_number)\n",
    "            dic['news_type'].append('Abstract')\n",
    "            dic['source_id'].append('')\n",
    "            dic['manual_id'].append('')\n",
    "            dic['article_title'].append(article_title)\n",
    "            dic['url'].append(article_url)\n",
    "            dic['authors'].append(article_author)\n",
    "            dic['author_affiliation'].append(article_aff)\n",
    "            dic['abstract_text'].append(article_abs_text)\n",
    "            dic['date'].append(article_date)\n",
    "            dic['start_time'].append(art_time.split('–')[0])\n",
    "            try:\n",
    "                dic['end_time'].append(art_time.split('–')[1])\n",
    "            except:\n",
    "                dic['end_time'].append('sess ka' + session_time.split('–')[1])\n",
    "            dic['location'].append(session_loc)\n",
    "            dic['session_title'].append(session_title)\n",
    "            dic['session_type'].append(sess_type)\n",
    "            dic['category'].append(category)\n",
    "            dic['sub_category'].append('')\n",
    "            dic['disclosure'].append(art_disclose)\n",
    "       \n",
    "    c += 1\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd92b395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf463b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dic)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d476c969",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('SIR_all.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fe58e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d87fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c7761b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2370cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9dc391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3a4abc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047d775c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baba5d61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b79494",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5affe1a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173044ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee76321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f516b9f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6e9033",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc077bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51fd662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071aa79b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dae6303",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
