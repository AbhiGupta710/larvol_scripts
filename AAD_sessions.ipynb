{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473c7c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import pandas as pd\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common import by\n",
    "import time\n",
    "\n",
    "def get_press_disclose(soup):\n",
    "    press = ''\n",
    "    disclose = ''\n",
    "    \n",
    "    for i in soup.find_all(class_='meeting-app-info-block mx-0'):\n",
    "\n",
    "        if i.find(class_='meeting-app-info-header row').text == 'Session Schedule':\n",
    "            press = i\n",
    "        elif i.find(class_='meeting-app-info-header row').text == 'Disclosures':\n",
    "            disclose = i\n",
    "\n",
    "    return press, disclose\n",
    "\n",
    "def clean_semicolon(st):\n",
    "    return re.sub(';$|; $', '', st, flags=re.S)\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://am2023.aad.org/sessions#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db92fd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "soupOut = BS(driver.page_source, 'html.parser')\n",
    "all_links = []\n",
    "for li in soupOut.find_all(class_='meeting-app-info-block')[3:]:\n",
    "    \n",
    "    url = li.find('a').get('href')\n",
    "    session_url = f'https://am2023.aad.org{url}'\n",
    "    all_links.append(session_url)\n",
    "    \n",
    "dic = {\n",
    "    'source_id':[],\n",
    "    'manual_id':[],\n",
    "    'article_title':[],\n",
    "    'url':[],\n",
    "    'authors':[],\n",
    "    'author_affiliation':[],\n",
    "    'abstract_text':[],\n",
    "    'date':[],\n",
    "    'start_time':[],\n",
    "    'end_time':[],\n",
    "    'location':[],\n",
    "    'session_id':[],\n",
    "    'news_type':[],\n",
    "    'session_title':[],\n",
    "    'session_type':[],\n",
    "    'category':[],\n",
    "    'sub_category':[],\n",
    "    'disclosure':[],\n",
    "    'handouts':[]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b0766a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e97fd24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c = 0\n",
    "\n",
    "for url in all_links[:109]:\n",
    "    \n",
    "    session_url = url\n",
    "    driver.get(session_url)\n",
    "    time.sleep(8)\n",
    "    soup = BS(driver.page_source, 'html.parser')\n",
    "    session_title = soup.find('h1').text\n",
    "\n",
    "    # ------------------- date and time -------------------\n",
    "    time_date = soup.find('span', class_='mx-2').parent\n",
    "    session_date = time_date.text.strip().split('|')[0].strip()\n",
    "    session_time = time_date.text.strip().split('|')[1].strip()\n",
    "\n",
    "    # ------------------------- abstract text -------------------------\n",
    "    session_text = ''\n",
    "    for i in list(soup.find(class_='land-page-hr').next_siblings):\n",
    "        if (re.search('Description', i.text) or re.search('Learning Objectives', i.text)) and list(i.children)[0].name == 'h2':\n",
    "            for j in list(i.children):\n",
    "                session_text += j.text.strip() + ' '\n",
    "\n",
    "\n",
    "\n",
    "    # ---------------------- location, type, category -----------------------\n",
    "    session_loca = ''\n",
    "    session_type = ''\n",
    "    session_cate = ''\n",
    "\n",
    "    for i in soup.find(class_='col-lg-4 p-1').find(class_='meeting-app-info-body').find_all(class_='row meeting-app-info-item'):\n",
    "\n",
    "        if re.search('Location', i.text):\n",
    "            session_loca = i.text\n",
    "\n",
    "        elif re.search('Type', i.text):\n",
    "            for typ in i.find_all('span'):\n",
    "                session_type += typ.text.strip() + '; '\n",
    "\n",
    "        elif re.search('Categories', i.text):\n",
    "            for cat in i.find_all('span'):\n",
    "                session_cate += cat.text.strip() +'; '\n",
    "\n",
    "    session_cate = clean_semicolon(session_cate)\n",
    "    session_type = clean_semicolon(session_type)\n",
    "\n",
    "\n",
    "    # --------------------------- authors -----------------\n",
    "    session_author = ''\n",
    "    handout_nhiMila = True\n",
    "    for i in soup.find_all(class_='meeting-app-info-block'):\n",
    "\n",
    "        if i.find(class_='meeting-app-info-header row').text == 'Directors/Co-Directors':\n",
    "\n",
    "            for au in i.find_all(class_='row meeting-app-info-item'):\n",
    "                session_author += au.text.strip() + '; '\n",
    "\n",
    "        elif i.find(class_='meeting-app-info-header row').text == 'Speakers':\n",
    "            for au in i.find_all(class_='row meeting-app-info-item'):\n",
    "                session_author += au.text.strip() + '; '\n",
    "\n",
    "        elif i.find(class_='meeting-app-info-header row').text == 'Handouts':\n",
    "            dic['handouts'].append(i)\n",
    "            handout_nhiMila = False\n",
    "\n",
    "    if handout_nhiMila:\n",
    "        dic['handouts'].append('')\n",
    "\n",
    "    session_author = clean_semicolon(session_author)\n",
    "\n",
    "    # ----------------------------- session disclosure ---------------------------\n",
    "    sess_disclosure = ''\n",
    "\n",
    "    if get_press_disclose(soup)[1]: # if disclosures are present\n",
    "        for i in get_press_disclose(soup)[1].find_all(class_='row meeting-app-info-item'):\n",
    "            auth = i.find('h5').text.strip()\n",
    "            dis = i.find('div').text.strip()\n",
    "            dis = dis.replace(';', ' ')\n",
    "\n",
    "            sess_disclosure += auth + ' : ' + dis + '; '\n",
    "\n",
    "    sess_disclosure = re.sub(';$|; $', '', sess_disclosure, flags=re.S)\n",
    "\n",
    "    print(f'sess title :- {session_title}')\n",
    "    print(f'sess date :- {session_date}')\n",
    "    print(f'sess time :- {session_time}')\n",
    "    print(f'sess auth :- {session_author}')\n",
    "    print(f'sess loca :- {session_loca}')\n",
    "    print(f'sess type :- {session_type}')\n",
    "    print(f'sess cate :- {session_cate}')\n",
    "\n",
    "    # print(f'sess text :- {session_text}')\n",
    "    # print(f'sess diss :- {sess_disclosure}')\n",
    "\n",
    "    dic['session_id'].append(f'S{c+1}')\n",
    "    dic['news_type'].append('Session')\n",
    "    dic['source_id'].append('')\n",
    "    dic['manual_id'].append('')\n",
    "    dic['article_title'].append(session_title)\n",
    "    dic['url'].append(session_url)\n",
    "    dic['authors'].append(session_author)\n",
    "    dic['author_affiliation'].append('')\n",
    "    dic['abstract_text'].append(session_text)\n",
    "    dic['date'].append(session_date)\n",
    "    dic['start_time'].append(session_time.split('-')[0].strip())\n",
    "    dic['end_time'].append(session_time.split('-')[-1].strip())\n",
    "    dic['location'].append(session_loca)\n",
    "    dic['session_title'].append(session_title)\n",
    "    dic['session_type'].append(session_type)\n",
    "    dic['category'].append(session_cate)\n",
    "    dic['sub_category'].append('')\n",
    "    dic['disclosure'].append(sess_disclosure)\n",
    "\n",
    "    print('========'*15)\n",
    "\n",
    "    # --------------------- pressentaion --------------------------\n",
    "    if get_press_disclose(soup)[0]: # if presentaions are present\n",
    "        for i in get_press_disclose(soup)[0].find_all(class_='row meeting-app-info-item'):\n",
    "\n",
    "            article_title = i.find(class_='m-0 font-weight-bold').text.strip()\n",
    "            article_time = i.find(class_='col-md-3').text.strip()\n",
    "            article_author = i.find(class_='font-italic m-0').text.strip()\n",
    "\n",
    "            print(f'art title :- {article_title}')\n",
    "            print(f'art time :- {article_time}')\n",
    "            print(f'art author :- {article_author}')\n",
    "\n",
    "            dic['session_id'].append(f'S{c+1}')\n",
    "            dic['news_type'].append('Abstract')\n",
    "            dic['source_id'].append('')\n",
    "            dic['manual_id'].append('')\n",
    "            dic['article_title'].append(article_title)\n",
    "            dic['url'].append(session_url)\n",
    "            dic['authors'].append(article_author)\n",
    "            dic['author_affiliation'].append('')\n",
    "            dic['abstract_text'].append('')\n",
    "            dic['date'].append(session_date)\n",
    "            dic['start_time'].append(article_time)\n",
    "            dic['end_time'].append('')\n",
    "            dic['location'].append(session_loca)\n",
    "            dic['session_title'].append(session_title)\n",
    "            dic['session_type'].append(session_type)\n",
    "            dic['category'].append(session_cate)\n",
    "            dic['sub_category'].append('')\n",
    "            dic['disclosure'].append('')\n",
    "            dic['handouts'].append('')\n",
    "            print('*==*='*15)\n",
    "\n",
    "    c += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c04cc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b2a825",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dic)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f1735f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cf5bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a599d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1885ab18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52037a23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d732adc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18abe75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f88ca31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc0fe52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
