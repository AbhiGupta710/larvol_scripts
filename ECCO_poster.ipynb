{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e211e448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import re\n",
    "import pandas as pd\n",
    "import bs4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635b4cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "req = requests.get('https://www.ecco-ibd.eu/publications/congress-abstracts/category/abstracts-2023.html')\n",
    "soupou = BS(req.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eed2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {\n",
    "    'source_id':[],\n",
    "    'manual_id':[],\n",
    "    'article_title':[],\n",
    "    'url':[],\n",
    "    'authors':[],\n",
    "    'author_affiliation':[],\n",
    "    'abstract_text':[],\n",
    "    'date':[],\n",
    "    'start_time':[],\n",
    "    'end_time':[],\n",
    "    'location':[],\n",
    "    'session_id':[],\n",
    "    'news_type':[],\n",
    "    'session_title':[],\n",
    "    'session_type':[],\n",
    "    'category':[],\n",
    "    'sub_category':[],\n",
    "    'disclosure':[],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8e11f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type_co = 5\n",
    "se_co = 842\n",
    "for i in soupou.find_all(class_='category')[5:]:\n",
    "    \n",
    "    session_type = i.find('h2').a.text.strip()\n",
    "    print(f'------------------ {session_type} ---------------------')\n",
    "    url = i.find('h2').a.get('href')\n",
    "    sess_link = f'https://www.ecco-ibd.eu{url}'\n",
    "    \n",
    "    req = requests.get(sess_link)\n",
    "    soup = BS(req.content, 'html.parser')\n",
    "    \n",
    "    if soup.find(class_='category'):\n",
    "        print('boht cat =----------------')\n",
    "        \n",
    "        for sin in soup.find_all(class_='category'):\n",
    "\n",
    "            url = sin.find('h2').a.get('href')\n",
    "            cat_link = f'https://www.ecco-ibd.eu{url}'\n",
    "            session_title = sin.find('h2').a.text.strip()\n",
    "            req = requests.get(cat_link)\n",
    "            soup = BS(req.content, 'html.parser')\n",
    "\n",
    "\n",
    "            for pos in soup.find(class_='items').children:\n",
    "                if pos == '\\n':\n",
    "                    continue\n",
    "\n",
    "                url = pos.find('a').get('href')\n",
    "                pos_link = f'https://www.ecco-ibd.eu{url}'\n",
    "                req = requests.get(pos_link)\n",
    "                soupre = BS(req.content, 'html.parser')\n",
    "                print(pos_link)\n",
    "                \n",
    "                post_title = soupre.find(class_='pos-title').text.strip()\n",
    "                auth_aff = soupre.find(class_='element element-textarea first')\n",
    "                post_auth = auth_aff.find_all('p')[0].text.strip()\n",
    "                post_aff = auth_aff.find_all('p')[1].text.strip()\n",
    "\n",
    "                abs_text = ''\n",
    "                for te in soupre.find(class_='element element-textarea first').next_siblings:\n",
    "                    if type(te) == bs4.element.Tag:\n",
    "                        for acha_text in list(te.children):\n",
    "                            if acha_text != '\\n':\n",
    "                                abs_text += acha_text.text + ' '\n",
    "\n",
    "                abs_text = abs_text.strip()\n",
    "                print(f'tit :- {post_title}')\n",
    "                print(f'aurh :- {post_auth}')\n",
    "                print(f'aff :- {post_aff}')\n",
    "                print(f'textt :- {abs_text}')\n",
    "                print('======'*18)\n",
    "                \n",
    "                dic['session_id'].append(f'S{se_co+1}')\n",
    "                dic['news_type'].append('Abstract')\n",
    "                dic['source_id'].append('')\n",
    "                dic['manual_id'].append('')\n",
    "                dic['article_title'].append(post_title)\n",
    "                dic['url'].append(pos_link)\n",
    "                dic['authors'].append(post_auth)\n",
    "                dic['author_affiliation'].append(post_aff)\n",
    "                dic['abstract_text'].append(abs_text)\n",
    "                dic['date'].append('')\n",
    "                dic['start_time'].append('')\n",
    "                dic['end_time'].append('')\n",
    "                dic['location'].append('')\n",
    "                dic['session_title'].append(session_title)\n",
    "                dic['session_type'].append(session_type)\n",
    "                dic['category'].append('')\n",
    "                dic['sub_category'].append('')\n",
    "                dic['disclosure'].append('')\n",
    "                \n",
    "            se_co += 1\n",
    "            \n",
    "    else:\n",
    "        for pos in soup.find(class_='items').children:\n",
    "            if pos == '\\n':\n",
    "                continue\n",
    "\n",
    "            url = pos.find('a').get('href')\n",
    "            pos_link = f'https://www.ecco-ibd.eu{url}'\n",
    "            \n",
    "            req = requests.get(pos_link)\n",
    "            soupre = BS(req.content, 'html.parser')\n",
    "            \n",
    "            print(pos_link)\n",
    "            \n",
    "            post_title = soupre.find(class_='pos-title').text.strip()\n",
    "            auth_aff = soupre.find(class_='element element-textarea first')\n",
    "            post_auth = auth_aff.find_all('p')[0].text.strip()\n",
    "            post_aff = auth_aff.find_all('p')[1].text.strip()\n",
    "\n",
    "            abs_text = ''\n",
    "            for te in soupre.find(class_='element element-textarea first').next_siblings:\n",
    "                if type(te) == bs4.element.Tag:\n",
    "                    for acha_text in list(te.children):\n",
    "                        if acha_text != '\\n':\n",
    "                            abs_text += acha_text.text + ' '\n",
    "\n",
    "            abs_text = abs_text.strip()\n",
    "            print(f'tit :- {post_title}')\n",
    "            print(f'aurh :- {post_auth}')\n",
    "            print(f'aff :- {post_aff}')\n",
    "            print(f'textt :- {abs_text}')\n",
    "            print('======'*18)\n",
    "            \n",
    "            dic['session_id'].append(f'S{se_co+1}')\n",
    "            dic['news_type'].append('Session')\n",
    "            dic['source_id'].append('')\n",
    "            dic['manual_id'].append('')\n",
    "            dic['article_title'].append(post_title)\n",
    "            dic['url'].append(pos_link)\n",
    "            dic['authors'].append(post_auth)\n",
    "            dic['author_affiliation'].append(post_aff)\n",
    "            dic['abstract_text'].append(abs_text)\n",
    "            dic['date'].append('')\n",
    "            dic['start_time'].append('')\n",
    "            dic['end_time'].append('')\n",
    "            dic['location'].append('')\n",
    "            dic['session_title'].append('')\n",
    "            dic['session_type'].append(session_type)\n",
    "            dic['category'].append('')\n",
    "            dic['sub_category'].append('')\n",
    "            dic['disclosure'].append('')\n",
    "            \n",
    "            se_co += 1\n",
    "    type_co += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31958a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5735427f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28413ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dic)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d6e2ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200f10ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('ECCO_2ndLink.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c3d870",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3782ddab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682ef13a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ba6c08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b1f5a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6bbf87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03289c63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
